{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incorporate-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np \n",
    "import re\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "human-cheese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter',\n",
       " '1',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'truth',\n",
       " 'universally',\n",
       " 'acknowledged',\n",
       " 'that',\n",
       " 'a',\n",
       " 'single',\n",
       " 'man',\n",
       " 'in',\n",
       " 'possession',\n",
       " 'of',\n",
       " 'a',\n",
       " 'good',\n",
       " 'fortune',\n",
       " 'must',\n",
       " 'be',\n",
       " 'in',\n",
       " 'want',\n",
       " 'of',\n",
       " 'a',\n",
       " 'wife']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open (\"pandp.txt\", \"r\") as myfile:\n",
    "  data=myfile.read().replace(\"\\n\", \" \")\n",
    "data = (data).split(\". \")\n",
    "input_seq = []\n",
    "for i in range(len(data)):\n",
    "    sent = re.sub(r'[^\\w\\s]', '', data[i]) \n",
    "    sent = sent.lower()\n",
    "    sent = sent.split()\n",
    "    input_seq.append(sent)\n",
    "(input_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subsequent-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for sentence in input_seq:\n",
    "\tfor i in range(1, len(sentence)):\n",
    "\t\tn_gram_sequence = sentence[:i+1]\n",
    "\t\tsentences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "derived-bryan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6940"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = []\n",
    "for sentence in (sentences):\n",
    "  for word in sentence:\n",
    "     word = re.sub(r'[^\\w\\s]', '', word) \n",
    "     word = word.lower()\n",
    "     all_words.append(word)\n",
    "\n",
    "all_words = list(set(all_words))\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "convertible-blame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_dict(all_words):\n",
    "    word_dict = {}\n",
    "    for idx, words in enumerate(all_words):\n",
    "        word_dict[words] = idx+1\n",
    "    return word_dict\n",
    "\n",
    "max_sequence_len = max([len(x) for x in sentences])\n",
    "def bag_of_word(tokenize_sen,wordict):\n",
    "    bg_token = np.zeros((max_sequence_len))\n",
    "    for idx,token in enumerate(tokenize_sen):\n",
    "        if token in wordict.keys():\n",
    "            bg_token[max_sequence_len - len(tokenize_sen)+idx] = wordict[token]   #prepadding\n",
    "        else:\n",
    "            bg_token[idx]= -1.0     # assign -1 to words not present in allwords\n",
    "    return bg_token\n",
    "max_sequence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "future-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = word_dict(all_words=all_words)\n",
    "tokenized = []\n",
    "for sentence in sentences:\n",
    "  tokenized.append(bag_of_word(sentence, word_index))\n",
    "\n",
    "# #Now sentences are prepadded and tokenized\n",
    "tokenized_sen_num = np.array(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "optimum-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, labels = tokenized_sen_num[:,:-1],tokenized_sen_num[:,-1]\n",
    "(tokenized_sen_num).shape\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=len(all_words)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intimate-contributor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n",
      "3636/3636 [==============================] - 82s 22ms/step - loss: 6.4763 - accuracy: 0.0529\n",
      "Epoch 2/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 5.5152 - accuracy: 0.1175\n",
      "Epoch 3/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 5.1180 - accuracy: 0.1438\n",
      "Epoch 4/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 4.8786 - accuracy: 0.1615\n",
      "Epoch 5/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 4.6765 - accuracy: 0.1744\n",
      "Epoch 6/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 4.5112 - accuracy: 0.1858\n",
      "Epoch 7/160\n",
      "3636/3636 [==============================] - 80s 22ms/step - loss: 4.3478 - accuracy: 0.1981\n",
      "Epoch 8/160\n",
      "3636/3636 [==============================] - 84s 23ms/step - loss: 4.2155 - accuracy: 0.2099\n",
      "Epoch 9/160\n",
      "3636/3636 [==============================] - 83s 23ms/step - loss: 4.0591 - accuracy: 0.2258\n",
      "Epoch 10/160\n",
      "3636/3636 [==============================] - 82s 22ms/step - loss: 3.9336 - accuracy: 0.23760s - loss: 3.9333 - \n",
      "Epoch 11/160\n",
      "3636/3636 [==============================] - 86s 24ms/step - loss: 3.7935 - accuracy: 0.2558\n",
      "Epoch 12/160\n",
      "3636/3636 [==============================] - 88s 24ms/step - loss: 3.6952 - accuracy: 0.2701\n",
      "Epoch 13/160\n",
      "3636/3636 [==============================] - 89s 25ms/step - loss: 3.5933 - accuracy: 0.2807\n",
      "Epoch 14/160\n",
      "3636/3636 [==============================] - 89s 25ms/step - loss: 3.4871 - accuracy: 0.2981\n",
      "Epoch 15/160\n",
      "3636/3636 [==============================] - 90s 25ms/step - loss: 3.3824 - accuracy: 0.3143\n",
      "Epoch 16/160\n",
      "3636/3636 [==============================] - 89s 24ms/step - loss: 3.2923 - accuracy: 0.3261\n",
      "Epoch 17/160\n",
      "3636/3636 [==============================] - 91s 25ms/step - loss: 3.2161 - accuracy: 0.3381\n",
      "Epoch 18/160\n",
      "3636/3636 [==============================] - 91s 25ms/step - loss: 3.1329 - accuracy: 0.3543\n",
      "Epoch 19/160\n",
      "3636/3636 [==============================] - 91s 25ms/step - loss: 3.0654 - accuracy: 0.3662\n",
      "Epoch 20/160\n",
      "3636/3636 [==============================] - 88s 24ms/step - loss: 2.9985 - accuracy: 0.3763\n",
      "Epoch 21/160\n",
      "3636/3636 [==============================] - 82s 23ms/step - loss: 2.9294 - accuracy: 0.3877\n",
      "Epoch 22/160\n",
      "3636/3636 [==============================] - 82s 23ms/step - loss: 2.8595 - accuracy: 0.4010\n",
      "Epoch 23/160\n",
      "3636/3636 [==============================] - 82s 23ms/step - loss: 2.8103 - accuracy: 0.4107\n",
      "Epoch 24/160\n",
      "3636/3636 [==============================] - 82s 23ms/step - loss: 2.7518 - accuracy: 0.4202\n",
      "Epoch 25/160\n",
      "3636/3636 [==============================] - 83s 23ms/step - loss: 2.7161 - accuracy: 0.4241\n",
      "Epoch 26/160\n",
      "3636/3636 [==============================] - 82s 23ms/step - loss: 2.6692 - accuracy: 0.4346\n",
      "Epoch 27/160\n",
      "3636/3636 [==============================] - 82s 23ms/step - loss: 2.6147 - accuracy: 0.4430\n",
      "Epoch 28/160\n",
      "3636/3636 [==============================] - 90s 25ms/step - loss: 2.5672 - accuracy: 0.4545\n",
      "Epoch 29/160\n",
      "3636/3636 [==============================] - 84s 23ms/step - loss: 2.5322 - accuracy: 0.4598\n",
      "Epoch 30/160\n",
      "3636/3636 [==============================] - 83s 23ms/step - loss: 2.4938 - accuracy: 0.4660\n",
      "Epoch 31/160\n",
      "3636/3636 [==============================] - 82s 23ms/step - loss: 2.4531 - accuracy: 0.4740\n",
      "Epoch 32/160\n",
      "3636/3636 [==============================] - 89s 25ms/step - loss: 2.4219 - accuracy: 0.4812\n",
      "Epoch 33/160\n",
      "3636/3636 [==============================] - 92s 25ms/step - loss: 2.3851 - accuracy: 0.4867\n",
      "Epoch 34/160\n",
      "3636/3636 [==============================] - 93s 26ms/step - loss: 2.3573 - accuracy: 0.4923\n",
      "Epoch 35/160\n",
      "3636/3636 [==============================] - 92s 25ms/step - loss: 2.3389 - accuracy: 0.4950\n",
      "Epoch 36/160\n",
      "3636/3636 [==============================] - 91s 25ms/step - loss: 2.3018 - accuracy: 0.5034\n",
      "Epoch 37/160\n",
      "3636/3636 [==============================] - 92s 25ms/step - loss: 2.2744 - accuracy: 0.5084\n",
      "Epoch 38/160\n",
      "3636/3636 [==============================] - 91s 25ms/step - loss: 2.2357 - accuracy: 0.5152\n",
      "Epoch 39/160\n",
      "3636/3636 [==============================] - 85s 23ms/step - loss: 2.2160 - accuracy: 0.5194\n",
      "Epoch 40/160\n",
      "3636/3636 [==============================] - 85s 23ms/step - loss: 2.1911 - accuracy: 0.5233\n",
      "Epoch 41/160\n",
      "3636/3636 [==============================] - 86s 24ms/step - loss: 2.1824 - accuracy: 0.5250\n",
      "Epoch 42/160\n",
      "3636/3636 [==============================] - 84s 23ms/step - loss: 2.1630 - accuracy: 0.5297\n",
      "Epoch 43/160\n",
      "3636/3636 [==============================] - 86s 24ms/step - loss: 2.1463 - accuracy: 0.5316\n",
      "Epoch 44/160\n",
      "3636/3636 [==============================] - 85s 23ms/step - loss: 2.1104 - accuracy: 0.5403\n",
      "Epoch 45/160\n",
      "3636/3636 [==============================] - 85s 23ms/step - loss: 2.0946 - accuracy: 0.5417\n",
      "Epoch 46/160\n",
      "3636/3636 [==============================] - 85s 23ms/step - loss: 2.0670 - accuracy: 0.5484\n",
      "Epoch 47/160\n",
      "3636/3636 [==============================] - 81s 22ms/step - loss: 2.0598 - accuracy: 0.5516\n",
      "Epoch 48/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 2.0349 - accuracy: 0.5557\n",
      "Epoch 49/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 2.0118 - accuracy: 0.5590\n",
      "Epoch 50/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 1.9993 - accuracy: 0.5594\n",
      "Epoch 51/160\n",
      "3636/3636 [==============================] - 79s 22ms/step - loss: 1.9695 - accuracy: 0.5642\n",
      "Epoch 52/160\n",
      "3636/3636 [==============================] - 88s 24ms/step - loss: 1.9717 - accuracy: 0.5670\n",
      "Epoch 53/160\n",
      "3636/3636 [==============================] - 88s 24ms/step - loss: 1.9427 - accuracy: 0.5734\n",
      "Epoch 54/160\n",
      "3636/3636 [==============================] - 88s 24ms/step - loss: 1.9307 - accuracy: 0.5754\n",
      "Epoch 55/160\n",
      "3636/3636 [==============================] - 83s 23ms/step - loss: 1.9103 - accuracy: 0.5767\n",
      "Epoch 56/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 1.9084 - accuracy: 0.5798\n",
      "Epoch 57/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 1.8873 - accuracy: 0.5828\n",
      "Epoch 58/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 1.8814 - accuracy: 0.5845\n",
      "Epoch 59/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 1.8548 - accuracy: 0.5891\n",
      "Epoch 60/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 1.8403 - accuracy: 0.5911\n",
      "Epoch 61/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 1.8407 - accuracy: 0.5895\n",
      "Epoch 62/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 1.8206 - accuracy: 0.5949\n",
      "Epoch 63/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 1.8126 - accuracy: 0.5965\n",
      "Epoch 64/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 1.7906 - accuracy: 0.6009\n",
      "Epoch 65/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 1.7683 - accuracy: 0.60540s - loss:\n",
      "Epoch 66/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 1.7538 - accuracy: 0.6067\n",
      "Epoch 67/160\n",
      "3636/3636 [==============================] - 78s 22ms/step - loss: 1.7582 - accuracy: 0.6093\n",
      "Epoch 68/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.7371 - accuracy: 0.6114\n",
      "Epoch 69/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.7359 - accuracy: 0.6115\n",
      "Epoch 70/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.7199 - accuracy: 0.6141\n",
      "Epoch 71/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.6910 - accuracy: 0.6223\n",
      "Epoch 72/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.6867 - accuracy: 0.6226\n",
      "Epoch 73/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.6783 - accuracy: 0.6231\n",
      "Epoch 74/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.6736 - accuracy: 0.6238\n",
      "Epoch 75/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.6601 - accuracy: 0.6268\n",
      "Epoch 76/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.6399 - accuracy: 0.6317\n",
      "Epoch 77/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.6372 - accuracy: 0.6301\n",
      "Epoch 78/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.6191 - accuracy: 0.6348\n",
      "Epoch 79/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.6048 - accuracy: 0.6366\n",
      "Epoch 80/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.6002 - accuracy: 0.6385\n",
      "Epoch 81/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.5891 - accuracy: 0.6405\n",
      "Epoch 82/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.5876 - accuracy: 0.6413\n",
      "Epoch 83/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.5645 - accuracy: 0.6478\n",
      "Epoch 84/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.5527 - accuracy: 0.6481\n",
      "Epoch 85/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.5575 - accuracy: 0.6469\n",
      "Epoch 86/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.5365 - accuracy: 0.6508\n",
      "Epoch 87/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.5327 - accuracy: 0.6538\n",
      "Epoch 88/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.5307 - accuracy: 0.6517\n",
      "Epoch 89/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.5163 - accuracy: 0.6553\n",
      "Epoch 90/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.5089 - accuracy: 0.6556\n",
      "Epoch 91/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4988 - accuracy: 0.6596\n",
      "Epoch 92/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.5007 - accuracy: 0.6589\n",
      "Epoch 93/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4738 - accuracy: 0.6647\n",
      "Epoch 94/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4659 - accuracy: 0.6633\n",
      "Epoch 95/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4632 - accuracy: 0.6636\n",
      "Epoch 96/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4589 - accuracy: 0.6698\n",
      "Epoch 97/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4532 - accuracy: 0.6679\n",
      "Epoch 98/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4455 - accuracy: 0.6679\n",
      "Epoch 99/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4416 - accuracy: 0.6683\n",
      "Epoch 100/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4439 - accuracy: 0.6687\n",
      "Epoch 101/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4225 - accuracy: 0.6735\n",
      "Epoch 102/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4264 - accuracy: 0.6720\n",
      "Epoch 103/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4197 - accuracy: 0.6732\n",
      "Epoch 104/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4059 - accuracy: 0.6774\n",
      "Epoch 105/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4126 - accuracy: 0.6754\n",
      "Epoch 106/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.4012 - accuracy: 0.6776\n",
      "Epoch 107/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3917 - accuracy: 0.6805\n",
      "Epoch 108/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3831 - accuracy: 0.6801\n",
      "Epoch 109/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3870 - accuracy: 0.6816\n",
      "Epoch 110/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3696 - accuracy: 0.6844\n",
      "Epoch 111/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3764 - accuracy: 0.6832\n",
      "Epoch 112/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3752 - accuracy: 0.6820\n",
      "Epoch 113/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3584 - accuracy: 0.6850\n",
      "Epoch 114/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3534 - accuracy: 0.6867\n",
      "Epoch 115/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3648 - accuracy: 0.6841\n",
      "Epoch 116/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3547 - accuracy: 0.6863\n",
      "Epoch 117/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3393 - accuracy: 0.6888\n",
      "Epoch 118/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3429 - accuracy: 0.6890\n",
      "Epoch 119/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3418 - accuracy: 0.6888\n",
      "Epoch 120/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3237 - accuracy: 0.6925\n",
      "Epoch 121/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3117 - accuracy: 0.6950\n",
      "Epoch 122/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3305 - accuracy: 0.6906\n",
      "Epoch 123/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3113 - accuracy: 0.6931\n",
      "Epoch 124/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3071 - accuracy: 0.6942\n",
      "Epoch 125/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3131 - accuracy: 0.6941\n",
      "Epoch 126/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2889 - accuracy: 0.6975\n",
      "Epoch 127/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.3044 - accuracy: 0.6928\n",
      "Epoch 128/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2762 - accuracy: 0.7026\n",
      "Epoch 129/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2965 - accuracy: 0.6976\n",
      "Epoch 130/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2843 - accuracy: 0.6986\n",
      "Epoch 131/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2795 - accuracy: 0.7000\n",
      "Epoch 132/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2774 - accuracy: 0.7002\n",
      "Epoch 133/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2681 - accuracy: 0.7028\n",
      "Epoch 134/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2747 - accuracy: 0.7012\n",
      "Epoch 135/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2746 - accuracy: 0.7003\n",
      "Epoch 136/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2710 - accuracy: 0.7033\n",
      "Epoch 137/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2684 - accuracy: 0.7010\n",
      "Epoch 138/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2693 - accuracy: 0.7007\n",
      "Epoch 139/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2487 - accuracy: 0.7081\n",
      "Epoch 140/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2632 - accuracy: 0.7045\n",
      "Epoch 141/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2555 - accuracy: 0.7041\n",
      "Epoch 142/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2507 - accuracy: 0.7047\n",
      "Epoch 143/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2537 - accuracy: 0.7053\n",
      "Epoch 144/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2451 - accuracy: 0.7074\n",
      "Epoch 145/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2459 - accuracy: 0.7048\n",
      "Epoch 146/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2333 - accuracy: 0.7098\n",
      "Epoch 147/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2340 - accuracy: 0.7095\n",
      "Epoch 148/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2384 - accuracy: 0.7083\n",
      "Epoch 149/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2334 - accuracy: 0.7070\n",
      "Epoch 150/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2278 - accuracy: 0.7116\n",
      "Epoch 151/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2369 - accuracy: 0.7071\n",
      "Epoch 152/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2371 - accuracy: 0.7064\n",
      "Epoch 153/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2262 - accuracy: 0.7105\n",
      "Epoch 154/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2286 - accuracy: 0.7092\n",
      "Epoch 155/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2063 - accuracy: 0.7136\n",
      "Epoch 156/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2248 - accuracy: 0.7085\n",
      "Epoch 157/160\n",
      "3636/3636 [==============================] - 78s 21ms/step - loss: 1.2141 - accuracy: 0.7135\n",
      "Epoch 158/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2099 - accuracy: 0.7143\n",
      "Epoch 159/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2143 - accuracy: 0.7129\n",
      "Epoch 160/160\n",
      "3636/3636 [==============================] - 77s 21ms/step - loss: 1.2195 - accuracy: 0.7125\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(len(all_words)+1, 128, input_length=max_sequence_len-1))\n",
    "  model.add(Bidirectional(LSTM(64)))\n",
    "  model.add(Dense(len(all_words)+1, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  history = model.fit(xs, ys, epochs=160, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "thirty-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aware-enzyme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "molecular-ground",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 165) for input KerasTensor(type_spec=TensorSpec(shape=(None, 165), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 166).\n"
     ]
    }
   ],
   "source": [
    "input_text = \"how are\"\n",
    "next_words = 1\n",
    "\n",
    "input_text = str(input_text).lower()\n",
    "input_text = input_text.split()\n",
    "inp = bag_of_word(input_text, word_index)\n",
    "inp = np.reshape(inp,(1,166))\n",
    "predict = model.predict(inp, verbose=0)\n",
    "predicted = np.argmax(predict,axis=1)\n",
    "\n",
    "output_word = \"\"\n",
    "for word, idx in word_index.items():\n",
    "    if idx == predicted:\n",
    "      output_word = (word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "immediate-turtle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_word #Predicted word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-dinner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
